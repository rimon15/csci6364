{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 5:  CSCI 6364/4364\n",
    "\n",
    "In this assignment, you will become familiar with the deep learning library Pytorch through the construction of a feed-forward neural network and a convolutional neural network applied to the MNIST dataset.  In various parts of the notebook, there will be places to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and use the MNIST dataset from Homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = \"data_mnist.csv\"\n",
    "df = pd.read_csv(dataset_filename)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use my own data-loading, which I used for the mnist dataset in previous homeworks\n",
    "def import_data(fname):\n",
    "    data_arr = []\n",
    "\n",
    "    with open(fname) as csv_file:\n",
    "        data_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in data_reader:\n",
    "            data_arr.append(row)\n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = import_data(\"data_mnist.csv\")\n",
    "y =  np.array([int(e[0]) for e in data_arr[1::]])\n",
    "X =  np.array([np.array(e[1::], dtype='uint8') for e in data_arr[1::]])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300,)\n",
      "(6300, 784)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor).to(device) # need .to(device) to actually use cuda?\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor).to(device) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor).to(device) \n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor).to(device) # data type is long\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = 784\n",
    "output_dim = 10\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,output_dim)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    " \n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 14.431194\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 0.538039\t Accuracy:68.260%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 0.404149\t Accuracy:76.269%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 1.032198\t Accuracy:80.091%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.186923\t Accuracy:82.167%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.226431\t Accuracy:83.503%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.206797\t Accuracy:84.593%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.391301\t Accuracy:85.390%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.791081\t Accuracy:86.027%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.467837\t Accuracy:86.662%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.553463\t Accuracy:87.138%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.209098\t Accuracy:87.704%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.091053\t Accuracy:88.124%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.350644\t Accuracy:88.470%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.268430\t Accuracy:88.730%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.151700\t Accuracy:88.994%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.037050\t Accuracy:89.287%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.169500\t Accuracy:89.553%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.249683\t Accuracy:89.800%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.066736\t Accuracy:90.053%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.272197\t Accuracy:90.200%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.163447\t Accuracy:90.360%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.184864\t Accuracy:90.523%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.092227\t Accuracy:96.875%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.039338\t Accuracy:94.363%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.044047\t Accuracy:94.524%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.177540\t Accuracy:94.288%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.094786\t Accuracy:94.356%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.079513\t Accuracy:94.360%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.071217\t Accuracy:94.498%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.113979\t Accuracy:94.462%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.571413\t Accuracy:94.475%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.193474\t Accuracy:94.505%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.393417\t Accuracy:94.586%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.071502\t Accuracy:94.674%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.097599\t Accuracy:94.650%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.233297\t Accuracy:94.676%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.058283\t Accuracy:94.691%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.129490\t Accuracy:94.745%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.039621\t Accuracy:94.776%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.070557\t Accuracy:94.771%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.322715\t Accuracy:94.811%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.181853\t Accuracy:94.877%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.168224\t Accuracy:94.936%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.037328\t Accuracy:94.981%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.086068\t Accuracy:94.993%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.025021\t Accuracy:100.000%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.090334\t Accuracy:95.159%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.068617\t Accuracy:95.266%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.452602\t Accuracy:95.199%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.065441\t Accuracy:95.569%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.081006\t Accuracy:95.630%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.070863\t Accuracy:95.629%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.070659\t Accuracy:95.762%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.382109\t Accuracy:95.807%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.439257\t Accuracy:95.829%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.179944\t Accuracy:95.827%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.024656\t Accuracy:95.922%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.022622\t Accuracy:95.944%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.134143\t Accuracy:96.073%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.096528\t Accuracy:96.068%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.161787\t Accuracy:96.043%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.045940\t Accuracy:96.025%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.175940\t Accuracy:95.983%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.508980\t Accuracy:95.945%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.059787\t Accuracy:95.965%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.067733\t Accuracy:95.970%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.075910\t Accuracy:95.977%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.046637\t Accuracy:95.958%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.016718\t Accuracy:100.000%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.056289\t Accuracy:95.895%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.100153\t Accuracy:95.978%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.451504\t Accuracy:95.840%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.018685\t Accuracy:95.802%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.065140\t Accuracy:95.842%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.013921\t Accuracy:95.878%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.149496\t Accuracy:95.976%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.189567\t Accuracy:96.033%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.144866\t Accuracy:96.161%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.187785\t Accuracy:96.208%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.093977\t Accuracy:96.183%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.041069\t Accuracy:96.126%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.257825\t Accuracy:96.193%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.044071\t Accuracy:96.215%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.116969\t Accuracy:96.205%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.023923\t Accuracy:96.227%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.111677\t Accuracy:96.199%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.325031\t Accuracy:96.206%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.100941\t Accuracy:96.241%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.177445\t Accuracy:96.282%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.157953\t Accuracy:96.286%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.111028\t Accuracy:96.296%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.017254\t Accuracy:100.000%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.038900\t Accuracy:97.059%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.078470\t Accuracy:97.123%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.267748\t Accuracy:96.854%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.280162\t Accuracy:96.906%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.032407\t Accuracy:96.900%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.084146\t Accuracy:96.813%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.021233\t Accuracy:96.804%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.287334\t Accuracy:96.820%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.151225\t Accuracy:96.917%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.350913\t Accuracy:96.894%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.232765\t Accuracy:96.858%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.015416\t Accuracy:96.807%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.111510\t Accuracy:96.865%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.040425\t Accuracy:96.893%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.032525\t Accuracy:96.896%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.024036\t Accuracy:96.906%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.228395\t Accuracy:96.901%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.335346\t Accuracy:96.892%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.014553\t Accuracy:96.888%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.156577\t Accuracy:96.878%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.384134\t Accuracy:96.866%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.148392\t Accuracy:96.835%\n"
     ]
    }
   ],
   "source": [
    "mlp = mlp.to(device) # need to specify the device for the model itself?\n",
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.eval()              # turn the model to evaluate mode\n",
    "index = 200\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor).to(device)\n",
    "image = torch_X_test[index].float().unsqueeze(0)\n",
    "true_label = y_test[index]\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = mlp(image).argmax()   #gets the prediction for the image's class\n",
    "plt.imshow(image.cpu().numpy().reshape(28,28), cmap='gray_r'); # need to reshape to (28, 28) rather than (28, 28, 1), and use .cpu() to go back from cuda to numpy ?\n",
    "print(true_label)\n",
    "print(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35700, 1, 28, 28])\n",
      "torch.Size([6300, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch_X_train.view(-1, 1,28,28).float()\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float()\n",
    "print(torch_X_train.shape)\n",
    "print(torch_X_test.shape)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN().to(device)\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 18.775633\t Accuracy:0.000%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 1.782842\t Accuracy:17.647%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 1.383891\t Accuracy:30.600%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 0.864492\t Accuracy:41.556%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.656621\t Accuracy:50.093%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.441207\t Accuracy:55.914%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.556965\t Accuracy:60.413%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.630217\t Accuracy:63.515%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.621140\t Accuracy:66.365%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.563681\t Accuracy:68.598%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.980275\t Accuracy:70.553%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.319063\t Accuracy:72.142%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.565857\t Accuracy:73.445%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.232893\t Accuracy:74.693%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.181844\t Accuracy:75.785%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.253259\t Accuracy:76.714%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.212853\t Accuracy:77.684%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.416366\t Accuracy:78.478%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.501527\t Accuracy:79.159%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.339230\t Accuracy:79.791%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.279948\t Accuracy:80.260%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.078110\t Accuracy:80.771%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.133036\t Accuracy:81.253%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.262927\t Accuracy:93.750%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.143791\t Accuracy:90.502%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.279148\t Accuracy:90.873%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.087797\t Accuracy:91.474%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.083051\t Accuracy:92.024%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.169379\t Accuracy:92.343%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.289241\t Accuracy:92.213%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.123270\t Accuracy:92.192%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.203754\t Accuracy:92.238%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.463900\t Accuracy:92.427%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.446179\t Accuracy:92.577%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.124451\t Accuracy:92.616%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.094473\t Accuracy:92.710%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.259604\t Accuracy:92.819%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.101255\t Accuracy:92.885%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.105619\t Accuracy:92.897%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.156450\t Accuracy:92.997%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.106670\t Accuracy:93.045%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.315528\t Accuracy:93.133%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.175867\t Accuracy:93.198%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.069262\t Accuracy:93.197%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.099826\t Accuracy:93.176%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.202436\t Accuracy:93.214%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.306117\t Accuracy:93.750%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.173150\t Accuracy:93.444%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.262350\t Accuracy:93.998%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.072420\t Accuracy:93.957%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.146995\t Accuracy:94.170%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.122177\t Accuracy:94.136%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.044150\t Accuracy:94.186%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.086394\t Accuracy:94.240%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.397587\t Accuracy:94.334%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.368333\t Accuracy:94.464%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.251333\t Accuracy:94.561%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.131143\t Accuracy:94.521%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.144831\t Accuracy:94.546%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.220488\t Accuracy:94.484%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.172057\t Accuracy:94.428%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.285439\t Accuracy:94.358%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.147832\t Accuracy:94.343%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.184394\t Accuracy:94.367%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.219697\t Accuracy:94.412%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.205866\t Accuracy:94.437%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.091352\t Accuracy:94.402%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.197253\t Accuracy:94.389%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.018935\t Accuracy:94.360%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.318332\t Accuracy:96.875%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.151665\t Accuracy:95.221%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.097137\t Accuracy:94.926%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.078123\t Accuracy:95.033%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.187113\t Accuracy:95.180%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.255956\t Accuracy:95.070%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.040707\t Accuracy:95.089%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.125629\t Accuracy:95.094%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.232449\t Accuracy:95.036%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.212538\t Accuracy:94.970%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.257996\t Accuracy:95.041%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.068578\t Accuracy:95.071%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.049356\t Accuracy:95.066%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.186664\t Accuracy:95.065%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.060675\t Accuracy:95.083%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.132088\t Accuracy:95.065%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.206936\t Accuracy:95.037%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.609035\t Accuracy:95.032%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.111515\t Accuracy:94.992%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.235805\t Accuracy:94.999%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.091493\t Accuracy:95.017%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.105060\t Accuracy:95.020%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.170961\t Accuracy:95.033%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.001042\t Accuracy:100.000%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.294996\t Accuracy:94.424%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.087499\t Accuracy:94.585%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.272310\t Accuracy:94.599%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.128335\t Accuracy:94.636%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.272235\t Accuracy:94.684%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.132430\t Accuracy:94.705%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.121843\t Accuracy:94.738%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.121463\t Accuracy:94.771%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.120207\t Accuracy:94.921%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.256330\t Accuracy:95.041%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.092063\t Accuracy:94.992%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.124676\t Accuracy:94.972%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.414177\t Accuracy:94.988%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.063852\t Accuracy:95.025%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.112319\t Accuracy:95.027%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.124312\t Accuracy:95.022%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.048469\t Accuracy:95.065%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.064574\t Accuracy:95.137%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.089929\t Accuracy:95.160%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.124894\t Accuracy:95.142%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.071191\t Accuracy:95.136%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.029183\t Accuracy:95.107%\n"
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.eval()              # turn the model to evaluate mode\n",
    "index = 100\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float().type(torch.LongTensor).to(device)\n",
    "image = torch_X_test[index].float().unsqueeze(0)\n",
    "true_label = y_test[index]\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = cnn(image).argmax()   #gets the prediction for the image's class\n",
    "plt.imshow(image.cpu().numpy().reshape(28,28), cmap='gray_r');\n",
    "print(true_label)\n",
    "print(class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the performance of the MLP and CNN models? Performance can include training time, accuracy, etc.\n",
    "\n",
    "As we can see, the MLP model performs with about the same accuracy as the CNN model. This is actually quite surprising, as I would expect the CNN to perform better in regards to accuracy as it encodes spatial information much better (but I guess since the mnist dataset is normalized, it doesn't make too much of a difference). In terms of performance, it was as expected, with the CNN having a shorter training time. Since the MLP has fully connected hidden layers, it will have many more parameters than the much more efficient CNN. Overall, the performance of the MLP and CNN are very similar, since the MNIST dataset does not contain temporal or spatial dependencies, and is completely normalized in terms of the pixels. However, the connections in the layers of the MLP increase the training time over the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit: Describe the below code and the output\n",
    "\n",
    "The code first selects a training sample, then outputs the class of the selected training sample. Then, the code gets the vector of predictions for each class (size 10, logits), and selects the one with highest probability. Then, the code enters the loop and set the highest probability index in the logit vector to -99 (very low), then it performs a gradient calculation on the loss between the original vector and the new vector. Then, in a forward pass, it updates the data in the x tensor with the calculated gradient and using the learning rate defined. Then, it prints the loss, highest probability from the first logit vector, and the highest probability from the new logit vector. Finally, it resets the gradient, subtracts the lowest value in the vector, and divides by the max value in the vector. Then, the loop runs but ends because the new max probability in the logit vector has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init idx: 9\n",
      "tensor([-9.2215e+00, -1.4424e+01, -1.1436e+01, -1.0727e+01, -4.4189e+00,\n",
      "        -9.7064e+00, -1.4597e+01, -8.8746e+00, -8.1842e+00, -1.2740e-02],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4.40618896484375 -0.012740408070385456 -4.418929576873779\n",
      "\n",
      "tensor(0.0039, device='cuda:0')\n",
      "tensor([-2.2003, -2.1637, -2.2784, -2.2960, -2.4335, -2.4191, -2.5590, -2.3052,\n",
      "        -2.1511, -2.2925], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Job done, breaking\n",
      "tensor([-2.2003, -2.1637, -2.2784, -2.2960, -2.4335, -2.4191, -2.5590, -2.3052,\n",
      "        -2.1511, -2.2925], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cnn\n",
    "#torch_X_test = torch_X_test.view(-1,1,28,28).float().type(torch.LongTensor)\n",
    "x = torch_X_test[index].float().clone()\n",
    "x.requires_grad_(True)\n",
    "#print(x.shape)\n",
    "with torch.no_grad():\n",
    "    logits = model(x.unsqueeze(0)).squeeze()\n",
    "    #print(logits.shape)\n",
    "    IMX = torch.argmax(logits)\n",
    "print(\"Init idx:\",IMX.item())\n",
    "    \n",
    "lr=.01 # learning rate?\n",
    "while True:\n",
    "    logits = model(x.unsqueeze(0)).squeeze()\n",
    "    print(logits)\n",
    "    \n",
    "    imx = torch.argmax(logits)\n",
    "    #print(imx)\n",
    "    if imx!=IMX: \n",
    "        print(\"Job done, breaking\")\n",
    "        break\n",
    "    y = logits.clone()\n",
    "    y[imx] = -99\n",
    "    loss = logits.max() - y.max() \n",
    "    loss.backward()\n",
    "    \n",
    "    #print(x.data.shape)\n",
    "    x.data.sub_(lr*x.grad.data)\n",
    "    print(loss.item(),logits.max().item(), y.max().item() )\n",
    "    print()\n",
    "    x.grad.data.zero_()\n",
    "    print(1/x.data.max())\n",
    "    x.data.sub_(x.data.min())\n",
    "    x.data.mul_(1/x.data.max())\n",
    "    \n",
    "with torch.no_grad():\n",
    "    print(model(x.unsqueeze(0)).squeeze())\n",
    "\n",
    "plt.imshow(x.detach().cpu().numpy().transpose(1,2,0).reshape(28,28));torch.argmax(model(x.unsqueeze(0))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
